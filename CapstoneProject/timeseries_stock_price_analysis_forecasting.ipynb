{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshit-Panapuzha/UCSD_Machine_Learning/blob/main/CapstoneProject/timeseries_stock_price_analysis_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQlTqNdpU7Ry"
      },
      "source": [
        "# <h1 style='background:red; border:0; border-radius: 10px; color:black'><center> INTRODUCTION </center></h1>\n",
        "## **What is a Time Series??**‚è≤üìà\n",
        "\n",
        "- **Time-series is series of obeservations that are recorded over a period of time. these observations are dependent of time component which can not be neglected thus we have have to analysis the this data keeping time component in mind.**\n",
        "\n",
        "<img src = \"https://miro.medium.com/max/1400/0*j8LjgYr1r1xPrJkr.gif\" width = 900 height = 400/>\n",
        "\n",
        "### **Time Series Forecasting**\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Time series forecasting is parhaps one of the most common type of machine learning techniques used in real-world scenarios. `time-sereis forecsting refers to predicting future values from historical data by statical analysis of trends and patterns from certain time-series data.` it falls under unsupervised learning category but called as a self-supervised learning or supervised learning technique. time-series data can be much complex to find patterns out of it, this is because irregular component of time series.\n",
        "</div>\n",
        "\n",
        "## **Use-cases and applications:**\n",
        "- Forecast product demand\n",
        "- Economic growth and population forecasting\n",
        "- Weather forecasting\n",
        "- Stock price forecasting\n",
        "- Sales/Revenue forecasting\n",
        "- Web-traffic forecasting\n",
        "\n",
        "\n",
        "## **Problem-statement**\n",
        "\n",
        "- In this notebook, our problem-statement is to analyse S&P500 stock prices (We will analyze 10 popular stocks and forecast the future prices) and build forecasting models that beat the market.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9K0QSTwU7R7"
      },
      "source": [
        "## Table of contents:\n",
        "\n",
        "**1) [Importing libraries](#lib)**\n",
        "\n",
        "**2) [Data analysis and visualizations](#viz)**\n",
        "\n",
        "   - **[Data cleaning](#cln)**\n",
        "   - **[What are the TOP 10 most traded stocks?](#top10)**\n",
        "   - **[Closing stock price visualization and what was the maximum price?](#close)**\n",
        "   - **[What was the trade volume during period of 2013-18?](#trade)**\n",
        "   - **[Comparative analysis of tech stocks](#tech)**\n",
        "   - **[Growth of stock price over a period of 2013-18](#growth)**\n",
        "   - **[Daily return of stock price analysis and hypothesis testing](#dr)**\n",
        "   \n",
        "**3) [Technical analysis of stocks using candle stick charts and Moving average](#ta)**\n",
        "\n",
        "   - **[Candlestick stock charts to visualize OHLC prices](#candle)**\n",
        "   - **[Moving average charts of 'FB' and 'AAPL'. which stock performed better?](#mav)**\n",
        "   \n",
        "**4) [Stock price forecasting: Modeling & forecasts](#forecast)**\n",
        "  \n",
        "   - **[Forecasting using Prophet](#prop)**\n",
        "   - **[Forecasting using Auto-ARIMA Models](#arima)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwFuGrH1U7R8"
      },
      "source": [
        "# <h1 style='background:green; border:0; border-radius: 10px; color:black'><center> Importing Libraries</center></h1>\n",
        "\n",
        "<a id='lib'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NueQokgcU7R8",
        "outputId": "c0b61601-80cf-452b-f7d2-5791aea18f92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import math\n",
        "from scipy import stats\n",
        "import matplotlib.dates as mdates\n",
        "from plotly import tools\n",
        "import plotly.tools as tls\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, plot, iplot\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "# matplotlib defaults\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFOhTpYXU7R9",
        "outputId": "8f58d9a5-0c89-435d-bc34-44f1176015b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.9b5-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.6)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.9b5\n"
          ]
        }
      ],
      "source": [
        "!pip install mplfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3DF78I3U7R9",
        "outputId": "9379a024-6e2e-424e-d51f-ae96248cb162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pystan==2.19.1.1\n",
            "  Downloading pystan-2.19.1.1-cp37-cp37m-manylinux1_x86_64.whl (67.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67.3 MB 98 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (0.29.32)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (1.21.6)\n",
            "Installing collected packages: pystan\n",
            "  Attempting uninstall: pystan\n",
            "    Found existing installation: pystan 3.3.0\n",
            "    Uninstalling pystan-3.3.0:\n",
            "      Successfully uninstalled pystan-3.3.0\n",
            "Successfully installed pystan-2.19.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fbprophet\n",
            "  Downloading fbprophet-0.7.1.tar.gz (64 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (0.29.32)\n",
            "Collecting cmdstanpy==0.9.5\n",
            "  Downloading cmdstanpy-0.9.5-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pystan>=2.14 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (2.19.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (3.2.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (2.4.0)\n",
            "Requirement already satisfied: holidays>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (0.16)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from fbprophet) (4.64.1)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->fbprophet) (0.5.11)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->fbprophet) (2.2.4)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->fbprophet) (0.3.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->fbprophet) (2022.6)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->fbprophet) (4.1.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->fbprophet) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->fbprophet) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->fbprophet) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->fbprophet) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->fbprophet) (1.15.0)\n",
            "Building wheels for collected packages: fbprophet\n",
            "  Building wheel for fbprophet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fbprophet: filename=fbprophet-0.7.1-py3-none-any.whl size=6638685 sha256=89ea6c7527e865a51961f927f1053814afb73b30f586e54f59328b4fc2088ec7\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a1/12/db63ff624de492fe6cccf676091a0860fdde2ffde4bc3280e2\n",
            "Successfully built fbprophet\n",
            "Installing collected packages: cmdstanpy, fbprophet\n",
            "  Attempting uninstall: cmdstanpy\n",
            "    Found existing installation: cmdstanpy 1.0.8\n",
            "    Uninstalling cmdstanpy-1.0.8:\n",
            "      Successfully uninstalled cmdstanpy-1.0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "prophet 1.1.1 requires cmdstanpy>=1.0.4, but you have cmdstanpy 0.9.5 which is incompatible.\u001b[0m\n",
            "Successfully installed cmdstanpy-0.9.5 fbprophet-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pystan==2.19.1.1\n",
        "!pip install fbprophet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nTccALi3U7R9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "019c7c92-e733-4340-f4bc-121997839d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-2.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.8 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.3.5)\n",
            "Collecting statsmodels>=0.13.2\n",
            "  Downloading statsmodels-0.13.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.9 MB 18.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.32)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.21.6)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.4.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->pmdarima) (3.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.13.2->pmdarima) (21.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.13.2->pmdarima) (0.5.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->statsmodels>=0.13.2->pmdarima) (3.0.9)\n",
            "Installing collected packages: statsmodels, pmdarima\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.12.2\n",
            "    Uninstalling statsmodels-0.12.2:\n",
            "      Successfully uninstalled statsmodels-0.12.2\n",
            "Successfully installed pmdarima-2.0.1 statsmodels-0.13.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "statsmodels"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P_Vhv4g6U7R-"
      },
      "outputs": [],
      "source": [
        "import mplfinance as mpf\n",
        "from fbprophet import Prophet\n",
        "from prophet.plot import plot_plotly, add_changepoints_to_plot\n",
        "import pmdarima as pm\n",
        "from pmdarima.arima.utils import ndiffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqMybgnrU7R-"
      },
      "source": [
        "# <h1 style='background:red; border:0; border-radius: 10px; color:black'><center> Data analysis and visualizations </center></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AdSCiLT0U7R-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "02e7db12-d18b-4426-8fe5-eb93aa7968c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f55cf6251d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_e287d_row0_col0, #T_e287d_row0_col1, #T_e287d_row0_col2, #T_e287d_row0_col3, #T_e287d_row0_col4, #T_e287d_row0_col5, #T_e287d_row0_col6, #T_e287d_row1_col0, #T_e287d_row1_col1, #T_e287d_row1_col2, #T_e287d_row1_col3, #T_e287d_row1_col4, #T_e287d_row1_col5, #T_e287d_row1_col6, #T_e287d_row2_col0, #T_e287d_row2_col1, #T_e287d_row2_col2, #T_e287d_row2_col3, #T_e287d_row2_col4, #T_e287d_row2_col5, #T_e287d_row2_col6, #T_e287d_row3_col0, #T_e287d_row3_col1, #T_e287d_row3_col2, #T_e287d_row3_col3, #T_e287d_row3_col4, #T_e287d_row3_col5, #T_e287d_row3_col6, #T_e287d_row4_col0, #T_e287d_row4_col1, #T_e287d_row4_col2, #T_e287d_row4_col3, #T_e287d_row4_col4, #T_e287d_row4_col5, #T_e287d_row4_col6 {\n",
              "  background-color: black;\n",
              "  color: lawngreen;\n",
              "  border: 1.5px  white;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_e287d_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >date</th>\n",
              "      <th class=\"col_heading level0 col1\" >open</th>\n",
              "      <th class=\"col_heading level0 col2\" >high</th>\n",
              "      <th class=\"col_heading level0 col3\" >low</th>\n",
              "      <th class=\"col_heading level0 col4\" >close</th>\n",
              "      <th class=\"col_heading level0 col5\" >volume</th>\n",
              "      <th class=\"col_heading level0 col6\" >Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_e287d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_e287d_row0_col0\" class=\"data row0 col0\" >2013-02-08</td>\n",
              "      <td id=\"T_e287d_row0_col1\" class=\"data row0 col1\" >15.070000</td>\n",
              "      <td id=\"T_e287d_row0_col2\" class=\"data row0 col2\" >15.120000</td>\n",
              "      <td id=\"T_e287d_row0_col3\" class=\"data row0 col3\" >14.630000</td>\n",
              "      <td id=\"T_e287d_row0_col4\" class=\"data row0 col4\" >14.750000</td>\n",
              "      <td id=\"T_e287d_row0_col5\" class=\"data row0 col5\" >8407500.000000</td>\n",
              "      <td id=\"T_e287d_row0_col6\" class=\"data row0 col6\" >AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e287d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_e287d_row1_col0\" class=\"data row1 col0\" >2013-02-11</td>\n",
              "      <td id=\"T_e287d_row1_col1\" class=\"data row1 col1\" >14.890000</td>\n",
              "      <td id=\"T_e287d_row1_col2\" class=\"data row1 col2\" >15.010000</td>\n",
              "      <td id=\"T_e287d_row1_col3\" class=\"data row1 col3\" >14.260000</td>\n",
              "      <td id=\"T_e287d_row1_col4\" class=\"data row1 col4\" >14.460000</td>\n",
              "      <td id=\"T_e287d_row1_col5\" class=\"data row1 col5\" >8882000.000000</td>\n",
              "      <td id=\"T_e287d_row1_col6\" class=\"data row1 col6\" >AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e287d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_e287d_row2_col0\" class=\"data row2 col0\" >2013-02-12</td>\n",
              "      <td id=\"T_e287d_row2_col1\" class=\"data row2 col1\" >14.450000</td>\n",
              "      <td id=\"T_e287d_row2_col2\" class=\"data row2 col2\" >14.510000</td>\n",
              "      <td id=\"T_e287d_row2_col3\" class=\"data row2 col3\" >14.100000</td>\n",
              "      <td id=\"T_e287d_row2_col4\" class=\"data row2 col4\" >14.270000</td>\n",
              "      <td id=\"T_e287d_row2_col5\" class=\"data row2 col5\" >8126000.000000</td>\n",
              "      <td id=\"T_e287d_row2_col6\" class=\"data row2 col6\" >AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e287d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_e287d_row3_col0\" class=\"data row3 col0\" >2013-02-13</td>\n",
              "      <td id=\"T_e287d_row3_col1\" class=\"data row3 col1\" >14.300000</td>\n",
              "      <td id=\"T_e287d_row3_col2\" class=\"data row3 col2\" >14.940000</td>\n",
              "      <td id=\"T_e287d_row3_col3\" class=\"data row3 col3\" >14.250000</td>\n",
              "      <td id=\"T_e287d_row3_col4\" class=\"data row3 col4\" >14.660000</td>\n",
              "      <td id=\"T_e287d_row3_col5\" class=\"data row3 col5\" >10259500.000000</td>\n",
              "      <td id=\"T_e287d_row3_col6\" class=\"data row3 col6\" >AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e287d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_e287d_row4_col0\" class=\"data row4 col0\" >2013-02-14</td>\n",
              "      <td id=\"T_e287d_row4_col1\" class=\"data row4 col1\" >14.940000</td>\n",
              "      <td id=\"T_e287d_row4_col2\" class=\"data row4 col2\" >14.960000</td>\n",
              "      <td id=\"T_e287d_row4_col3\" class=\"data row4 col3\" >13.160000</td>\n",
              "      <td id=\"T_e287d_row4_col4\" class=\"data row4 col4\" >13.990000</td>\n",
              "      <td id=\"T_e287d_row4_col5\" class=\"data row4 col5\" >31879900.000000</td>\n",
              "      <td id=\"T_e287d_row4_col6\" class=\"data row4 col6\" >AAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# read the dataframe\n",
        "df = pd.read_csv(\"all_stocks_5yr.csv\")\n",
        "df.head().style.set_properties(**{'background-color': 'black',\n",
        "                                    'color': 'lawngreen',\n",
        "                                    'border': '1.5px  white'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FVYLxpfKU7R-"
      },
      "outputs": [],
      "source": [
        "# define simple function get all the information needed\n",
        "def information_func(df):\n",
        "    \n",
        "    # unique stocks\n",
        "    print(\"Uniques stocks available in dataset:\", df['Name'].nunique())\n",
        "    print(\"----\"*20)\n",
        "    \n",
        "    # metadata of dataset\n",
        "    print(\"Metadata of the dataset:\\n\")\n",
        "    df.info()\n",
        "    print(\"----\"*20)\n",
        "    \n",
        "    # missing values\n",
        "    null = df.isnull().sum()\n",
        "    print(null)\n",
        "    print(\"----\"*20)\n",
        "    \n",
        "    # max range of stocks dataset\n",
        "    delta = (pd.to_datetime(df['date']).max() - pd.to_datetime(df['date']).min())\n",
        "    print(\"Time range of stocks dataset:\\n\", delta)\n",
        "    print(\"----\"*20) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vs1s-D4YU7R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaae2b07-43cf-4645-b1ea-522603affb02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uniques stocks available in dataset: 163\n",
            "--------------------------------------------------------------------------------\n",
            "Metadata of the dataset:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 197318 entries, 0 to 197317\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   date    197318 non-null  object \n",
            " 1   open    197315 non-null  float64\n",
            " 2   high    197316 non-null  float64\n",
            " 3   low     197315 non-null  float64\n",
            " 4   close   197317 non-null  float64\n",
            " 5   volume  197317 non-null  float64\n",
            " 6   Name    197317 non-null  object \n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 10.5+ MB\n",
            "--------------------------------------------------------------------------------\n",
            "date      0\n",
            "open      3\n",
            "high      2\n",
            "low       3\n",
            "close     1\n",
            "volume    1\n",
            "Name      1\n",
            "dtype: int64\n",
            "--------------------------------------------------------------------------------\n",
            "Time range of stocks dataset:\n",
            " 1825 days 00:00:00\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "information_func(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEq0ZpiFU7R_"
      },
      "source": [
        "### <h1 style='background:#4bd659; border:0; border-radius: 10px; color:black'><right> Data cleaning </right></h1>\n",
        "\n",
        "<a id='cln'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ohzLnhTZU7R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebd74a6-5163-410f-ac42-5e751d9c9c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 197314 entries, 0 to 197316\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count   Dtype         \n",
            "---  ------  --------------   -----         \n",
            " 0   date    197314 non-null  datetime64[ns]\n",
            " 1   open    197314 non-null  float64       \n",
            " 2   high    197314 non-null  float64       \n",
            " 3   low     197314 non-null  float64       \n",
            " 4   close   197314 non-null  float64       \n",
            " 5   volume  197314 non-null  float64       \n",
            " 6   ticks   197314 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(5), object(1)\n",
            "memory usage: 12.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# rename Name to ticks\n",
        "rdf = df.rename(columns={'Name':'ticks'})\n",
        "\n",
        "# drop the null as they a few values and time-series won't be affected by such values\n",
        "rdf.dropna(inplace=True)\n",
        "\n",
        "# change the dtype of date column\n",
        "new_df = rdf.copy()\n",
        "new_df.loc[:, 'date'] = pd.to_datetime(rdf.loc[:, 'date'], format='%Y/%m/%d')\n",
        "\n",
        "# new dataframe info\n",
        "new_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDA7O9GMU7R_"
      },
      "source": [
        "### <h1 style='background:#ed615c; border:0; border-radius: 10px; color:black'><right> Top 10 stock tickers by average trade volume </right></h1>\n",
        "<a id='top10'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "17h2sRWHU7R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354b9edc-f2c3-46b9-ca8c-7c55438a0e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the mean of ticks dictionary: 163\n",
            "Top 10 company tickers with highest average traded stock volume:\n",
            " Index(['BAC', 'AAPL', 'AMD', 'CSCO', 'CHK', 'CMCSA', 'C', 'AMAT', 'DAL',\n",
            "       'EBAY'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# find the average volume of each stocks using function and sort top 10 most traded stocks for further analysis \n",
        "mean_dict = {}\n",
        "\n",
        "# find average of volume traded over a period of time using for loops\n",
        "for key in new_df['ticks'].unique():\n",
        "    value = new_df[new_df['ticks'] == key ]['volume'].mean()\n",
        "    mean_dict[key]= value\n",
        "\n",
        "print(\"Length of the mean of ticks dictionary:\", len(mean_dict))\n",
        "\n",
        "# convert dict to pandas dataframe\n",
        "avaerage_s = pd.Series(mean_dict).transpose()\n",
        "top10_s = avaerage_s.sort_values(ascending=False)[:10]\n",
        "\n",
        "print(\"Top 10 company tickers with highest average traded stock volume:\\n\", top10_s.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3Jn9xmvOU7R_"
      },
      "outputs": [],
      "source": [
        "# function to return top 10 sub dataframe\n",
        "def subdataframe(df, tick):\n",
        "    \n",
        "    # top 10 ticks\n",
        "    ticks = list(top10_s.index)\n",
        "    \n",
        "    assert tick in ticks, \"\"\"Stock tick does not belong to top 10 stocks by trade volume, please try any of these:\\n\n",
        "    ['BAC', 'AAPL', 'GE', 'F', 'FB', 'MSFT', 'AMD', 'MU', 'INTC', 'CSCO']\"\"\"\n",
        "    \n",
        "    ndf = new_df[new_df['ticks'] == tick]\n",
        "    print(ndf)\n",
        "    return ndf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "agelM098U7SA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "86c1f18e-c44c-4d4d-f01d-7c3ecaabf445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            date   open   high    low   close       volume ticks\n",
            "72870 2013-02-08  11.86  11.90  11.72  11.760  145217221.0   BAC\n",
            "72871 2013-02-11  11.73  11.90  11.67  11.860  103499848.0   BAC\n",
            "72872 2013-02-12  11.87  12.34  11.78  12.245  231771561.0   BAC\n",
            "72873 2013-02-13  12.35  12.42  12.05  12.170  192478919.0   BAC\n",
            "72874 2013-02-14  12.09  12.27  12.07  12.130  143901737.0   BAC\n",
            "...          ...    ...    ...    ...     ...          ...   ...\n",
            "74124 2018-02-01  32.00  32.50  31.96  32.500   62367448.0   BAC\n",
            "74125 2018-02-02  32.44  32.67  31.86  31.950   96971924.0   BAC\n",
            "74126 2018-02-05  31.12  31.98  29.15  30.260  155908256.0   BAC\n",
            "74127 2018-02-06  29.41  31.29  29.30  31.200  165878399.0   BAC\n",
            "74128 2018-02-07  31.12  31.74  30.86  31.250  101180515.0   BAC\n",
            "\n",
            "[1259 rows x 7 columns]\n",
            "           date      open      high       low     close       volume ticks\n",
            "1259 2013-02-08   67.7142   68.4014   66.8928   67.8542  158168416.0  AAPL\n",
            "1260 2013-02-11   68.0714   69.2771   67.6071   68.5614  129029425.0  AAPL\n",
            "1261 2013-02-12   68.5014   68.9114   66.8205   66.8428  151829363.0  AAPL\n",
            "1262 2013-02-13   66.7442   67.6628   66.1742   66.7156  118721995.0  AAPL\n",
            "1263 2013-02-14   66.3599   67.3771   66.2885   66.6556   88809154.0  AAPL\n",
            "...         ...       ...       ...       ...       ...          ...   ...\n",
            "2513 2018-02-01  167.1650  168.6200  166.7600  167.7800   47230787.0  AAPL\n",
            "2514 2018-02-02  166.0000  166.8000  160.1000  160.5000   86593825.0  AAPL\n",
            "2515 2018-02-05  159.1000  163.8800  156.0000  156.4900   72738522.0  AAPL\n",
            "2516 2018-02-06  154.8300  163.7200  154.0000  163.0300   68243838.0  AAPL\n",
            "2517 2018-02-07  163.0850  163.4000  159.0685  159.5400   51608580.0  AAPL\n",
            "\n",
            "[1259 rows x 7 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-46b427549aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0maapl_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#ge_df = subdataframe(new_df, 'GE')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mf_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mfb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmsft_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MSFT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-48727d88a264>\u001b[0m in \u001b[0;36msubdataframe\u001b[0;34m(df, tick)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     assert tick in ticks, \"\"\"Stock tick does not belong to top 10 stocks by trade volume, please try any of these:\\n\n\u001b[0;32m----> 8\u001b[0;31m     ['BAC', 'AAPL', 'GE', 'F', 'FB', 'MSFT', 'AMD', 'MU', 'INTC', 'CSCO']\"\"\"\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mndf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Stock tick does not belong to top 10 stocks by trade volume, please try any of these:\n\n    ['BAC', 'AAPL', 'GE', 'F', 'FB', 'MSFT', 'AMD', 'MU', 'INTC', 'CSCO']"
          ]
        }
      ],
      "source": [
        "# company dict for respective ticks (TOP 10 STOCKS BY AVERAGE TRAE VOLUME)\n",
        "company_dict = {'BAC':'Bank of America', \n",
        "                'AAPL':'Apple', \n",
        "                'GE':'General Electric', \n",
        "                'F':'Ford Motor Company', \n",
        "                'FB':'Facebook', \n",
        "                'MSFT':'Microsoft', \n",
        "                'AMD':'Adavanced Micro Devices', \n",
        "                'MU':'Micron Technology', \n",
        "                'INTC':'Intel Corp', \n",
        "                'CSCO':'Cisco'\n",
        "               }\n",
        "\n",
        "bac_df = subdataframe(new_df, 'BAC')\n",
        "aapl_df = subdataframe(new_df, 'AAPL')\n",
        "ge_df = subdataframe(new_df, 'GE')\n",
        "f_df = subdataframe(new_df, 'F')\n",
        "fb_df = subdataframe(new_df, 'FB')\n",
        "msft_df = subdataframe(new_df, 'MSFT')\n",
        "amd_df = subdataframe(new_df, 'AMD')\n",
        "mu_df = subdataframe(new_df, 'MU')\n",
        "intc_df = subdataframe(new_df, 'INTC')\n",
        "csco_df = subdataframe(new_df, 'CSCO')\n",
        "\n",
        "\n",
        "# define a function to return daily return and company column\n",
        "def dailyfunc(df):\n",
        "    df['daily return'] = ((df['close'] - df['open'])/df['open'])*100\n",
        "    df.style.format('{:.2f}%', subset='daily return')\n",
        "    df['daily_mean'] = (df['open'] + df['close'] + df['high'] + df['low'])/4\n",
        "    df['co_name'] = company_dict[df['ticks'].unique()[0]]\n",
        "    return df\n",
        "\n",
        "bac_df = dailyfunc(bac_df)\n",
        "aapl_df = dailyfunc(aapl_df)\n",
        "ge_df = dailyfunc(ge_df)\n",
        "f_df = dailyfunc(f_df)\n",
        "fb_df = dailyfunc(fb_df)\n",
        "msft_df = dailyfunc(msft_df)\n",
        "amd_df = dailyfunc(amd_df)\n",
        "mu_df = dailyfunc(mu_df)\n",
        "intc_df = dailyfunc(intc_df)\n",
        "csco_df = dailyfunc(csco_df)\n",
        "\n",
        "print('\\t\\tStart Date\\t\\t\\t\\t\\tEnd Date')\n",
        "print(f\"BAC\\t\\t{bac_df['date'].min()}\\t\\t\\t{bac_df['date'].max()}\")\n",
        "print(f\"AAPL\\t\\t{aapl_df['date'].min()}\\t\\t\\t{aapl_df['date'].max()}\")\n",
        "print(f\"GE\\t\\t{ge_df['date'].min()}\\t\\t\\t{ge_df['date'].max()}\")\n",
        "print(f\"F\\t\\t{f_df['date'].min()}\\t\\t\\t{f_df['date'].max()}\")\n",
        "print(f\"FB\\t\\t{fb_df['date'].min()}\\t\\t\\t{fb_df['date'].max()}\")\n",
        "print(f\"MSFT\\t\\t{msft_df['date'].min()}\\t\\t\\t{msft_df['date'].max()}\")\n",
        "print(f\"AMD\\t\\t{amd_df['date'].min()}\\t\\t\\t{amd_df['date'].max()}\")\n",
        "print(f\"MU\\t\\t{mu_df['date'].min()}\\t\\t\\t{mu_df['date'].max()}\")\n",
        "print(f\"INTC\\t\\t{intc_df['date'].min()}\\t\\t\\t{intc_df['date'].max()}\")\n",
        "print(f\"CSCO\\t\\t{csco_df['date'].min()}\\t\\t\\t{csco_df['date'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QR2jtNQU7SA"
      },
      "source": [
        "### <h1 style='background:#4bd659; border:0; border-radius: 10px; color:black'><right> Closing stock price visualizations & maximum price during 5 years </right></h1>  \n",
        "<a id='close'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvATXbIZU7SA"
      },
      "outputs": [],
      "source": [
        "# function return closing stock price over a 5 years of time period\n",
        "def closing_stock_price(df):\n",
        "    \n",
        "    # define highest stock over 5 period of time with date of the same\n",
        "    high = df['close'].max()\n",
        "    datetime = df[df['close'] == df['close'].max()]['date'].values\n",
        "    \n",
        "    if df['ticks'].unique()[0] == 'GE':\n",
        "        fig, ax = plt.subplots(figsize=(10,6), facecolor='#ed615c')\n",
        "    elif df['ticks'].unique()[0] == 'F':\n",
        "        fig, ax = plt.subplots(figsize=(10,6), facecolor='#ed615c')\n",
        "    else:\n",
        "        fig, ax = plt.subplots(figsize=(10,6), facecolor='#4bd659')\n",
        "    ax.plot(df['date'], df['close'], color='#0f2113')\n",
        "    ax.set_title(f\"{df['co_name'].unique()[0]} stock price\", fontsize=20)\n",
        "    ax.set_xlabel(\"Date\", fontsize=15)\n",
        "    ax.set_ylabel(\"Daily closing stock price\", fontsize=15)\n",
        "    if df['ticks'].unique()[0] == 'AAPL':\n",
        "        ax.annotate(f\"All time high price during\\nfive year period\\nwas ${high}\", xy=(datetime, high),xytext=(datetime,high-35),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#f5d3bf', edgecolor='#d0d5db'),\n",
        "                 arrowprops=dict(facecolor='#f0190a',headlength=25, shrink=0.1))\n",
        "    elif df['ticks'].unique()[0] == 'F':\n",
        "        ax.annotate(f\"All time high price during\\nfive year period\\nwas ${high}\", xy=(datetime, high),xytext=(datetime,high-3),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#f5d3bf', edgecolor='#d0d5db'),\n",
        "                 arrowprops=dict(facecolor='#f0190a',headlength=25, shrink=0.1))\n",
        "    elif df['ticks'].unique()[0] == 'FB':\n",
        "        ax.annotate(f\"All time high price during\\nfive year period\\nwas ${high}\", xy=(datetime, high),xytext=(datetime,high-50),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#f5d3bf', edgecolor='#d0d5db'),\n",
        "                 arrowprops=dict(facecolor='#f0190a',headlength=25, shrink=0.1))\n",
        "    elif df['ticks'].unique()[0] == 'MSFT':\n",
        "        ax.annotate(f\"All time high price during\\nfive year period\\nwas ${high}\", xy=(datetime, high),xytext=(datetime,high-20),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#f5d3bf', edgecolor='#d0d5db'),\n",
        "                 arrowprops=dict(facecolor='#f0190a',headlength=25, shrink=0.1))\n",
        "    elif df['ticks'].unique()[0] == 'MU':\n",
        "        ax.annotate(f\"All time high price during\\nfive year period\\nwas ${high}\", xy=(datetime, high),xytext=(datetime,high-15),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#f5d3bf', edgecolor='#d0d5db'),\n",
        "                 arrowprops=dict(facecolor='#f0190a',headlength=25, shrink=0.1))\n",
        "    else:\n",
        "        ax.annotate(f\"All time high price during\\nfive year period\\nwas ${high}\", xy=(datetime, high),xytext=(datetime,high-10),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#f5d3bf', edgecolor='#d0d5db'),\n",
        "                 arrowprops=dict(facecolor='#f0190a',headlength=25, shrink=0.1))\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "# plot of all the closing stocks\n",
        "closing_stock_price(bac_df)\n",
        "closing_stock_price(aapl_df)\n",
        "closing_stock_price(ge_df)\n",
        "closing_stock_price(f_df)\n",
        "closing_stock_price(fb_df)\n",
        "closing_stock_price(msft_df)\n",
        "closing_stock_price(amd_df)\n",
        "closing_stock_price(mu_df)\n",
        "closing_stock_price(intc_df)\n",
        "closing_stock_price(csco_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPlJBKWHU7SA"
      },
      "source": [
        "**Key findings:**\n",
        "    \n",
        "- **We could find TOP 10 most traded stocks duing period of 2013-2018.**\n",
        "- **Out of 10 companies one is bank, 7 of them are tech companies, another two are non-tech lagacy companies namely General electric and Ford motors.**\n",
        "- **From closing stock price visualization, we can learn that stocks 'GE' and 'F' are declining and other tech stocks are rising over a five year period time.**\n",
        "- **As we can see visualizations are self-explanatory and we can learn all time high stock prices of all the tickers.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHND-m70U7SB"
      },
      "source": [
        "### **Lifecycle of companies and products:**\n",
        "\n",
        "- We can observe from above plots that stock prices of companies like FORD and GE are declining while teck companies' stocks are rising rapidly. this indicates course or lifecycle of companies.\n",
        "- In below image one can observe the lifecycle of any company or product from startup phase to decline stage. this is the most general theory in business that typical companies  follow such cycles.\n",
        "![image.png](attachment:0f30344f-5f2f-4200-a339-7813cae4e745.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc743PFaU7SB"
      },
      "source": [
        "### <h1 style='background:#ed615c; border:0; border-radius: 10px; color:black'><right> Trade volume of stocks over a period of 2013-2018 </right></h1>\n",
        "<a id='trade'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3FxZEg-U7SB"
      },
      "outputs": [],
      "source": [
        "# function to visualize trade volume of stocks\n",
        "def trade_vol(df):\n",
        "    \n",
        "    # x and y coords for average trade volume\n",
        "    ave_x = df['date'].mean()\n",
        "    ave_y = df['volume'].mean()\n",
        "    # y coord for max trade vol\n",
        "    max_y = df['volume'].max()\n",
        "    # y coord for min trade vol\n",
        "    min_y = df['volume'].min()\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10,6), facecolor='#4bd659')\n",
        "    ax.plot(df['date'], df['volume'], color='#283954')\n",
        "    ax.set_title(f\"{df['co_name'].unique()[0]} stock trade volume\", fontsize=20)\n",
        "    ax.set_xlabel(\"Date\", fontsize=15)\n",
        "    ax.set_ylabel(\"Daily trade volume\", fontsize=15)\n",
        "    ax.axhline(y=df['volume'].max(), linestyle='--', lw=2.2, color='green')\n",
        "    ax.axhline(y=df['volume'].min(), linestyle='--',lw=2.2, color='red')\n",
        "    ax.axhline(y=df['volume'].mean(), linestyle='--',lw=2.8, color='yellow')\n",
        "    ax.axvline(x=df[df['volume'] == max_y]['date'].values, ls='--', lw='2.2', color='#0aebff')\n",
        "    ax.annotate(f\"Average trade volume {round(df['volume'].mean(),2)}\", \n",
        "                xy=(ave_x,ave_y),xytext=(ave_x,ave_y + 10000000),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db')\n",
        "                 )\n",
        "    ax.annotate(f\"Maximum trade volume {df['volume'].max()}\", \n",
        "                xy=(ave_x,max_y),xytext=(ave_x,max_y - 1000000),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db')\n",
        "                 )\n",
        "    ax.annotate(f\"Minimum trade volume {df['volume'].min()}\", \n",
        "                xy=(ave_x,min_y),xytext=(ave_x,min_y - 1000000),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db')\n",
        "                 )\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "# plot of all stocks trade volume\n",
        "trade_vol(bac_df)\n",
        "trade_vol(aapl_df)\n",
        "trade_vol(ge_df)\n",
        "trade_vol(f_df)\n",
        "trade_vol(fb_df)\n",
        "trade_vol(msft_df)\n",
        "trade_vol(amd_df)\n",
        "trade_vol(mu_df)\n",
        "trade_vol(intc_df)\n",
        "trade_vol(csco_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOpAu61oU7SB"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- **Above visualizations depicts what was the maximum, minimum and average trade volume overa period of 2013-2018.**\n",
        "- **As visualizations are self-explanatory in nature we can also learn variance of trade volume for example stock ticker 'INTC' has a higest variance in trade volume compared other tickers.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKI7Rf-qU7SB"
      },
      "source": [
        "### <h1 style='background:#4bd659; border:0; border-radius: 10px; color:black'><right> Comparative analysis of 7 tech stocks </right></h1>  \n",
        "<a id='tech'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFCnTgi7U7SB"
      },
      "source": [
        "### What is comparative analysis of stocks in finance and investment industry?\n",
        "\n",
        "- **An important aspect of the fundamental analysis of stocks is comparing stocks of the same sector. The most basic way to analyse and compare stocks from the same sector is to conduct an analysis of different ratios like Earnings per share (EPS), Price-to-Earnings (P/E Ratio), Return on Equity (ROE), Return on Capital Employed (ROCE), and Debt-to-Equity ratios, and stock-prices of various companies, trade volume of stocks.**\n",
        "- **In this project, due to limited data of companies, we can only compare daily mean stock price of companies and can make inferences like stock price comparison and relative stock price fluctuations that I have mentioned below chart.**\n",
        "\n",
        "![image.png](attachment:d58c76f2-bc7b-4465-9ef2-df7dba41c157.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFQe5dfYU7SB"
      },
      "outputs": [],
      "source": [
        "# tech stocks price comparison\n",
        "fig, ax = plt.subplots(figsize=(14,7))\n",
        "ax.plot(fb_df['date'], fb_df['daily_mean'],label='FB', color='#f2f23f', lw=1.4)\n",
        "ax.plot(aapl_df['date'], aapl_df['daily_mean'],label='AAPL', color='#92f005', lw=1.4)\n",
        "ax.plot(mu_df['date'], mu_df['daily_mean'],label='MU', color='#f55c0a', lw=1.4)\n",
        "ax.plot(amd_df['date'], amd_df['daily_mean'],label='AMD', color='#0af5ba', lw=1.4)\n",
        "ax.plot(intc_df['date'], intc_df['daily_mean'],label='INTC', color='#0a93f5', lw=1.4)\n",
        "ax.plot(msft_df['date'], msft_df['daily_mean'],label='MSFT', color='#0a29f5', lw=1.4)\n",
        "ax.plot(csco_df['date'], csco_df['daily_mean'],label='CSCO', color='#c20af5', lw=1.4)\n",
        "ax.axvspan(*mdates.datestr2num(['2/1/2016','12/31/2017']), color='#e3aaa6')\n",
        "ax.set_title(\"Comparative analysis of tech stock prices\")\n",
        "ax.annotate(\"Years of growth for\\nApple,Micron tech and Facebook\", xy=(mdates.datestr2num('6/1/2016'),175),\n",
        "           bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db'))\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"Daily average stock price\")\n",
        "ax.legend(facecolor='#f27985', fontsize=\"medium\", title=\"Tech stock price analysis\", title_fontsize=13)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwA5X5qGU7SC"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- **It is very clear that 'FB' stock was one of the most expensive among all 7 tech stocks**\n",
        "- **stock ticker 'AMD' was among the cheapest to buy compared to other stocks**\n",
        "- **From above chart we can also conclude that stocks like 'FB' and 'AAPL' were also among the most volatile in nature than other stocks**\n",
        "\n",
        "### What is volatility?üëÄüìà\n",
        "\n",
        "> **In finance, volatility (usually denoted by œÉ) is the degree of variation of a trading price series over time, usually measured by the standard deviation of logarithmic returns.**\n",
        "> \n",
        "\n",
        "*source: wikipedia*\n",
        "\n",
        "**In layman terms, volatility is nothing but the fluctuation of stock price during given period of time**\n",
        "\n",
        "![image.png](attachment:3710fd6a-fef5-4c22-b2a3-335d68119b63.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzlnnSarU7SC"
      },
      "source": [
        "### <h1 style='background:#ed615c; border:0; border-radius: 10px; color:black'><right> Find out growth of stocks of the companies over a 5 years period </right></h1>\n",
        "<a id='growth'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T80KR53WU7SC"
      },
      "source": [
        " ### Growth of stock prices\n",
        "\n",
        "- **In finance and investment industry, stock price growth is really important metric one needs to measure to find out the how is stock or investment of an individual is growing**\n",
        "- **Below is the formula to find out growth of stock prices**\n",
        "\n",
        "*source: educba.com*\n",
        "\n",
        "![image.png](attachment:0712cf5f-a2fd-4aaf-9636-8ee4d9ae0c7b.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl8JS9FeU7SC"
      },
      "outputs": [],
      "source": [
        "# list of stock dataframes\n",
        "list_df = [bac_df, aapl_df, ge_df, f_df, fb_df, msft_df, amd_df, mu_df, intc_df, csco_df]\n",
        "\n",
        "# loop through the the list_df to find mini and maxi of each stocks \n",
        "mini = [df[df['date'] == df['date'].min()]['close'].values.item() for df in list_df]\n",
        "maxi = [df[df['date'] == df['date'].max()]['close'].values.item() for df in list_df]\n",
        "\n",
        "# find list of abosolute difference between both stock price\n",
        "diff = np.array(maxi) - np.array(mini)\n",
        "\n",
        "# find the percentage growth\n",
        "growth = (diff/mini)*100\n",
        "growth_list = growth.tolist()\n",
        "co_name_list = [df['co_name'].unique()[0] for df in list_df]\n",
        "\n",
        "# visualize the growth of the stocks\n",
        "fig, ax = plt.subplots(figsize=(13,7))\n",
        "ax.barh(y=co_name_list, width=growth_list, height=0.9, color=['#4bd659','#4bd659','#ed615c','#ed615c','#4bd659',\n",
        "                                                             '#4bd659','#4bd659','#4bd659','#4bd659','#4bd659'],\n",
        "       edgecolor='#713ae8')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{round(p.get_width(),2)}%', (p.get_width()+15, p.get_y() +0.3))\n",
        "ax.set_xlabel('Percentage growth in stock price')\n",
        "ax.set_ylabel('Name of companies')\n",
        "ax.set_title(\"Growth in stock price over a period of 5 years\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgaxI_rEU7SC"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- **We can observe that growth of stock 'Facebook' is the highest among all other 10 stocks over a period of 5 years**\n",
        "- **It is very much self-explanotary that stocks of 'Ford Motors' and 'General Electric' has given negative return over a years of period.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQii5-k1U7SC"
      },
      "source": [
        "### <h1 style='background:#4bd659; border:0; border-radius: 10px; color:black'><right> Daily return of stock prices analysis </right></h1>\n",
        "\n",
        "<a id='dr'></a>\n",
        "\n",
        "### Daily return hypothesis test\n",
        "\n",
        "- **In stock market, you will often hear that daily return of any stock price is 0% which means you will get zero return on your investment in one day.**\n",
        "- **So let's prove the hypothesis by analysing top 10 most traded stocks and assesing their daily return distribution in this section**\n",
        "\n",
        "- **H0: Daily return is zero**\n",
        "- **Ha: Daily return is not zero**\n",
        "\n",
        "- **We will prove this hypothesis as a one sample t-test as we know population mean but are not aware of std deviation. if p-value is greater than 0.05 than we can not reject the null hypothesis and if it is less than 0.05 than we have to reject the null hypothesis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tnbgRVQU7SC"
      },
      "outputs": [],
      "source": [
        "# python's scipy.stats module has ttest_1samp method we allows to prove this hypothesis\n",
        "result_dict = {}\n",
        "for df in list_df:\n",
        "    result = stats.ttest_1samp(df['daily return'], 0)\n",
        "    result_dict[df['ticks'].unique()[0]] = result   \n",
        "result_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74B0-w_5U7SC"
      },
      "source": [
        "- **From above results, we can learn that pvalues of stocks 'MSFT'.'INTC' and 'CSCO' are less than 0.05 so we can reject the null hypothesis and accept alternative hypothesis that is 'Daily return is not zero' while for other stocks we cannot reject null hypothesis.**\n",
        "\n",
        "- **Stistically it proves that 7 out of 10 have daily return of zero percentage which is the most general case.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqIhLJ_xU7SD"
      },
      "outputs": [],
      "source": [
        "###### function to plot daily return and histogram of 10 stocks\n",
        "def daily_return(df):\n",
        "    \n",
        "    # assign variables to annotation positions\n",
        "    ave_x = df['date'].mean()\n",
        "    y_max = df['daily return'].max()\n",
        "    y_max_date = df[df['daily return'] == df['daily return'].max()]['date'].values\n",
        "    dt = pd.to_datetime(y_max_date, '%Y%m%d%H%M%S')\n",
        "    xb = dt.item().date()\n",
        "    y_min = df['daily return'].min()\n",
        "    y_mean = df['daily return'].mean()\n",
        "    \n",
        "    plt.figure(figsize=(13,6), facecolor='#4bd659')\n",
        "    \n",
        "    plt.subplot(121)\n",
        "    plt.plot(df['date'], df['daily return'], color='#062e63')\n",
        "    plt.axhline(y=df['daily return'].max(), color='green', ls='--')\n",
        "    plt.axhline(y=df['daily return'].min(), color='red', ls='--')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(\"Percentage return\")\n",
        "    plt.annotate(f\"Min. daily return={round(df['daily return'].min(),2)}%\", \n",
        "                xy=(ave_x,y_min),xytext=(ave_x,y_min),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db')\n",
        "                 )\n",
        "    plt.annotate(f\"Max. daily return={round(df['daily return'].max(),2)}%\\nDate was={xb}\", \n",
        "                xy=(ave_x,y_max),xytext=(ave_x,y_max-0.6),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db', alpha=0.7)\n",
        "                 )\n",
        "    plt.title(f\"Daily return of stock {df['co_name'].unique()[0]}\")\n",
        "    \n",
        "    plt.subplot(122)\n",
        "    plt.hist(df['daily return'], density=True, color='#0f52a8')\n",
        "    plt.xlabel('Histogram')\n",
        "    plt.axvline(x=df['daily return'].mean(), color='yellow', ls='--')\n",
        "    if df['ticks'].unique()[0] == 'AMD':\n",
        "        plt.annotate(f\"Mean daily return={round(df['daily return'].mean(),2)}%\", \n",
        "                xy=(y_mean,0.10),xytext=(y_mean+2,0.10),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db'),\n",
        "                arrowprops=dict(arrowstyle=\"wedge,tail_width=1.\",facecolor='#e8e0ba', \n",
        "                            edgecolor='#d0d5db',\n",
        "                            relpos=(0.1,0.5)\n",
        "                            )\n",
        "                 )\n",
        "    elif df['ticks'].unique()[0] == 'MU':\n",
        "        plt.annotate(f\"Mean daily return={round(df['daily return'].mean(),2)}%\", \n",
        "                xy=(y_mean,0.12),xytext=(y_mean+1,0.12),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db'),\n",
        "                arrowprops=dict(arrowstyle=\"wedge,tail_width=1.\",facecolor='#e8e0ba', \n",
        "                            edgecolor='#d0d5db',\n",
        "                            relpos=(0.1,0.5)\n",
        "                            )\n",
        "                 )\n",
        "    else:\n",
        "        plt.annotate(f\"Mean daily return={round(df['daily return'].mean(),2)}%\", \n",
        "                xy=(y_mean,0.20),xytext=(y_mean+1,0.20),\n",
        "                bbox=dict(boxstyle=\"round\",facecolor='#e8e0ba', edgecolor='#d0d5db'),\n",
        "                arrowprops=dict(arrowstyle=\"wedge,tail_width=1.\",facecolor='#e8e0ba', \n",
        "                            edgecolor='#d0d5db',\n",
        "                            relpos=(0.1,0.5)\n",
        "                            )\n",
        "                 )\n",
        "    plt.title(f\"Histogram of stock price\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "# call the function with dataframe\n",
        "daily_return(bac_df)\n",
        "daily_return(aapl_df)\n",
        "daily_return(ge_df)\n",
        "daily_return(f_df)\n",
        "daily_return(fb_df)\n",
        "daily_return(msft_df)\n",
        "daily_return(amd_df)\n",
        "daily_return(mu_df)\n",
        "daily_return(intc_df)\n",
        "daily_return(csco_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGNcgQ8qU7SD"
      },
      "source": [
        "# <h1 style='background:red; border:0; border-radius: 10px; color:black'><right> Technical analysis of stocks using candle stick charts and moving average </right></h1>\n",
        "<a id='ta'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6XVIrnkU7SD"
      },
      "source": [
        "### Technical analysis of stocks\n",
        "\n",
        "- **An open-high-low-close chart (also OHLC) is a type of chart typically used to illustrate movements in the price of a financial instrument over time. Each vertical line on the chart shows the price range (the highest and lowest prices) over one unit of time, e.g., one day or one hour. Tick marks project from each side of the line indicating the opening price (e.g., for a daily bar chart this would be the starting price for that day) on the left, and the closing price for that time period on the right. The bars may be shown in different hues depending on whether prices rose or fell in that period.**\n",
        "\n",
        "*source: Wikipedia*\n",
        "\n",
        "![image.png](attachment:422da312-c37d-4824-ab3c-4ef82ff1c966.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZYeuxqBU7SD"
      },
      "outputs": [],
      "source": [
        "# using matplotlib/mplfinance tool\n",
        "F_df = f_df.copy()\n",
        "F_df.set_index('date', inplace=True)\n",
        "F_df\n",
        "mpf.plot(F_df.iloc[:60,:], type='candle', mav=(5,7), figratio=(9,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJswNm4MU7SD"
      },
      "source": [
        "### <h1 style='background:#4bd659; border:0; border-radius: 10px; color:black'><right> Candlestick charts of stocks to visualize OHLC prices </right></h1>\n",
        "<a id='candle'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWiJjMsDU7SD"
      },
      "outputs": [],
      "source": [
        "# using plotly graph_objs let's plot candlestick charts of stocks\n",
        "def candlestick_chart(df):\n",
        "    trace = go.Candlestick(x=df['date'],\n",
        "                          open=df['open'],\n",
        "                          high=df['high'],\n",
        "                          low=df['low'],\n",
        "                          close=df['close'])\n",
        "    layout = {\n",
        "    'title': f\"{df['co_name'].unique()[0]} Historical Stock Price\",\n",
        "    'xaxis': {'title': 'Date'\n",
        "             },\n",
        "    'yaxis': {'title': 'Stock Price (USD$)'}\n",
        "    }\n",
        "    data = [trace]\n",
        "    \n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    iplot(fig)\n",
        "    fig.update_layout(xaxis_rangeslider_visible=False, paper_bgcolor='#4bd659')\n",
        "    fig.show()\n",
        "    \n",
        "# plot the charts using this function\n",
        "candlestick_chart(bac_df)\n",
        "candlestick_chart(aapl_df)\n",
        "candlestick_chart(ge_df)\n",
        "candlestick_chart(f_df)\n",
        "candlestick_chart(fb_df)\n",
        "candlestick_chart(msft_df)\n",
        "candlestick_chart(amd_df)\n",
        "candlestick_chart(mu_df)\n",
        "candlestick_chart(intc_df)\n",
        "candlestick_chart(csco_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA8X2Q2TU7SE"
      },
      "source": [
        "### <h1 style='background:#ed615c; border:0; border-radius: 10px; color:black'><right> Moving Averages charts of Facebook and Apple </right></h1>\n",
        "<a id='mav'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIU_IjLMU7SE"
      },
      "source": [
        "### Moving average of stocks\n",
        "\n",
        "> A moving average (MA) is a stock indicator commonly used in technical analysis, used to help smooth out price data by creating a constantly updated average price. A rising moving average indicates that the security is in an uptrend, while a declining moving average indicates a downtrend. \n",
        "\n",
        "source: investopedia.com \n",
        "\n",
        "- **Moving average is one of the most widly used stock market forecasting method in finance industry, in this section we will plot and analyse stocks of 'FACEBOOK' and 'APPLE' using 10, 50 and 200 days moving averages to find uptrend and downtrends**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ET4znc3U7SE"
      },
      "outputs": [],
      "source": [
        "# define function to return copies of stock dataframe with moving averages\n",
        "def mav_function(df):\n",
        "    \n",
        "    # calclulate moving averages of 10,50 and 200 days\n",
        "    df['10_d_avg'] = df['close'].rolling(window=10).mean()\n",
        "    df['50_d_avg'] = df['close'].rolling(window=50).mean()\n",
        "    df['200_d_avg'] = df['close'].rolling(window=200).mean()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# let's analyse apple and facebook stocks using moving averages methods\n",
        "aapl_df = mav_function(aapl_df)\n",
        "fb_df = mav_function(fb_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt90IU7UU7SE"
      },
      "outputs": [],
      "source": [
        "# plot moving avearges charts of apple and facebook\n",
        "aapl_dfn = aapl_df.copy()\n",
        "fb_dfn = fb_df.copy()\n",
        "\n",
        "def mav_chart(df):\n",
        "    df = df.set_index('date')\n",
        "    \n",
        "    fig = tls.make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
        "    # set colors and cols names to be plotted\n",
        "    colors = ['#ff4500', '#92a1cf', '#6E6E6E']\n",
        "    avgs = ['10_d_avg','50_d_avg','200_d_avg']\n",
        "    \n",
        "    for col, c in zip(avgs, colors):\n",
        "        fig.append_trace({'x': df.index, 'y': df[col], 'type': 'scatter', 'name': col, 'line': {'color': c}},1,1)\n",
        "    for col in ['close']:\n",
        "        fig.append_trace({'x': df.index, 'y': df[col], 'type': 'scatter', 'name': 'closing price', 'line': {'color': '#393f5e'}},2,1)\n",
        "        \n",
        "    fig['layout'].update(height=800,title=f\"Relationship between Moving averages <br> and Closing Price of {df['co_name'].unique()[0]}\",\n",
        "                    paper_bgcolor='#4bd659', plot_bgcolor='#F2DFCE')\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGzz7lFWU7SE"
      },
      "source": [
        "## Moving average chart of 'FB'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIM280KPU7SE"
      },
      "outputs": [],
      "source": [
        "# plot the MAVs fo FB\n",
        "mav_chart(fb_dfn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzKMkcyGU7SE"
      },
      "source": [
        "**Analysis and Interpretation:**\n",
        "\n",
        "- **From above stock chart of 'FB' we can observe that 14th Novemeber, 2016 is the first when 10 Days Moving avearge is going down than 50 Days Moving average which shows declining trends** \n",
        "- **On 4th January, 2017 10 Days Moving average starts moving above 200 Days Moving average which shows Upwards trend in 'FB' stock**\n",
        "- **Over a period of 5 years FB showed upward trend except only one time which was around Dec. 2016, and reason of that decline was FB got into trouble by reports of 'Cambridge analytica Data scandle', thus stock declined in Dec. 2016**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIVBDwfXU7SE"
      },
      "source": [
        "## Moving average chart of 'AAPL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fl7kr_vU7SF"
      },
      "outputs": [],
      "source": [
        "# plot the MAVs of Apple\n",
        "mav_chart(aapl_dfn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTVvD87CU7SF"
      },
      "source": [
        "**Analysis and Interpretation:**\n",
        "\n",
        "- **Apple's stock price shows more irregular fluctuations compared to FB with one major decline during period of 2015-16.**\n",
        "- **Around 7th august 2015 10 Days Moving average of Apple's stock price goes below 200 Days Moving average which shows downward trend in apple's stock price.**\n",
        "- **And exactly, year after 15th august 2016, 10 Days Moving average crosses 200 Days Moving avearge which show uptrend thereafter.**\n",
        "\n",
        "- **By comparing stocks 'FB' and 'AAPL', we can conclude that 'FB' performed better than 'AAPL'. 'FB' showed more consistant growth as well as less fluctions than 'AAPL' which proves the performance of 'FB' stocks. My recommendation is to BUY 'FB' as it has great growth prospects.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQaqeaXuU7SF"
      },
      "source": [
        "# <h1 style='background:green; border:0; border-radius: 10px; color:black'><right> Stock price forecasting: Modelling and forecast </right></h1>\n",
        "<a id='forecast'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA_BPErVU7SF"
      },
      "source": [
        "### Forecasting Using Prophet\n",
        "<a id='prop'></a>\n",
        "\n",
        "> **Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.**\n",
        "> \n",
        "\n",
        "source: https://facebook.github.io/prophet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm5I3SdeU7SF"
      },
      "outputs": [],
      "source": [
        "# create function to return dataframe for forecating\n",
        "def df_formatting(df):\n",
        "    df = df.loc[:, ['date','close']]\n",
        "    df.rename(columns={'date':'ds', 'close':'y'}, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "aplph_df = df_formatting(aapl_df)\n",
        "fbph_df = df_formatting(fb_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSRsVOsdU7SF"
      },
      "outputs": [],
      "source": [
        "# forecasting using prophet\n",
        "def price_forecasting(df, period):\n",
        "    \n",
        "    prophet = Prophet(yearly_seasonality = 'auto')\n",
        "    prophet.fit(df)\n",
        "    future_price = prophet.make_future_dataframe(periods=period)\n",
        "    forecasts = prophet.predict(future_price)\n",
        "    forecast = forecasts[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
        "    \n",
        "    # plot the foreasts\n",
        "    fig = prophet.plot(forecasts)\n",
        "    a = add_changepoints_to_plot(fig.gca(), prophet, forecasts)\n",
        "    \n",
        "    # plot the components \n",
        "    fig2 = prophet.plot_components(forecasts)\n",
        "    \n",
        "    return forecasts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU3cHmp1U7SF"
      },
      "source": [
        "### <h1 style='background:#ed615c; border:0; border-radius: 10px; color:black'><right> 'AAPL' stock price forecasting  </right></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfpAv5tMU7SF"
      },
      "outputs": [],
      "source": [
        "forecast_aapl = price_forecasting(aplph_df, 365)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDYp0wyGU7SG"
      },
      "source": [
        "### <h1 style='background:#4bd659; border:0; border-radius: 10px; color:black'><right> 'FB' stock price forecasting </right></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60fKF8QWU7SG"
      },
      "outputs": [],
      "source": [
        "forecast_fb = price_forecasting(fbph_df, 365)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OM_xUceU7SG"
      },
      "source": [
        "### <h1 style='background:#ed615c; border:0; border-radius: 10px; color:black'><right> Forecasting using Auto-ARIMA models</right></h1>\n",
        "\n",
        "<a id='arima'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJZNr7PPU7SG"
      },
      "source": [
        "### Time-series decomposition\n",
        "\n",
        "> **Time series decomposition involves thinking of a series as a combination of level, trend, seasonality, and noise components.**\n",
        "> \n",
        "\n",
        "> **Decomposition provides a useful abstract model for thinking about time series generally and for better understanding problems during time series analysis and forecasting.**\n",
        "> \n",
        "\n",
        "Source: machinelearningmastery.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQwH-NOxU7SG"
      },
      "outputs": [],
      "source": [
        "# let's find seasonla decomposition of time-series models\n",
        "def decomposition(df, period):\n",
        "    # decompistion instance\n",
        "    result_decom = seasonal_decompose(df['y'], model=\"additive\", \n",
        "                                      period=period, extrapolate_trend='freq')\n",
        "    # plot the componenets \n",
        "    fig = result_decom.plot()\n",
        "    fig.set_size_inches((10, 6))\n",
        "    # Tight layout to realign things\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # capture the compoenets \n",
        "    trend = result_decom.trend\n",
        "    season = result_decom.seasonal\n",
        "    reside = result_decom.resid\n",
        "    return trend, season, reside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiffIViyU7SG"
      },
      "outputs": [],
      "source": [
        "# let's find compoenets for aapl stock price\n",
        "tr, se, re = decomposition(aplph_df, 365)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqk2qrRxU7SG"
      },
      "outputs": [],
      "source": [
        "# let's find out components for fb stock price\n",
        "ftr, fse, fre = decomposition(fbph_df, 365)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toSUq3ITU7SG"
      },
      "source": [
        "### Plot the autocorrelation and partial auto-correlation plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngi-pBGsU7SG"
      },
      "outputs": [],
      "source": [
        "# function to retunr acf and pacf plots\n",
        "def acf_pacf(df, lags):\n",
        "    var = df['y']\n",
        "    # plot the acf plot\n",
        "    fig = plot_acf(var, lags=lags)\n",
        "    fig.set_size_inches((9, 5))\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # plot the pacf plots\n",
        "    fig = plot_pacf(var, lags=lags)\n",
        "    fig.set_size_inches((9,5))\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDZ-2LApU7SH"
      },
      "outputs": [],
      "source": [
        "# acf and pacf of aapl stock \n",
        "acf_pacf(aplph_df, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YOPXMmJU7SH"
      },
      "outputs": [],
      "source": [
        "# acf and pacf plots of FB\n",
        "acf_pacf(fbph_df, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4pHs_XIU7SH"
      },
      "source": [
        "- **Auto-correlation interpretation - Slow decline in auto-correlation indicates time-series not stationary, we can prove the stationarity of time-series by Dicky-fuller test**\n",
        "\n",
        "- **Partical auto-correlation interpretation - For both stocks PACF suggest that time-series dependence can be captured only 1 lag owing to its significance than other laged time-series**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eadqdqfKU7SH"
      },
      "source": [
        "### Dicky-Fuller Test(Stationarity test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1q2Alq6U7SH"
      },
      "source": [
        "- **Hypothesis to prove dicky-fuller tests**\n",
        "\n",
        "**H0 - Beta = 1 (the time-series is non-stationary)**\n",
        "\n",
        "**HA - Beta < 1 (the time-series is stationary)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8FjP3w4U7SH"
      },
      "outputs": [],
      "source": [
        "# funtion to return adfuller test results\n",
        "def adfuller_test(df):\n",
        "    adfuller_result = adfuller(df['y'], autolag='AIC')\n",
        "    adfuller_output = pd.Series(adfuller_result[:4], index=['Test statistic', 'p-value',\n",
        "                                                           'Lags Used','Number of Observations Used'])\n",
        "    print(adfuller_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmyWkvVvU7SH"
      },
      "outputs": [],
      "source": [
        "print(\"adfuller test results for AAPLE\")\n",
        "adfuller_test(aplph_df)\n",
        "print(\"----\"*10)\n",
        "print(\"adfuller test results for FB\")\n",
        "adfuller_test(fbph_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5SfHKX8U7SH"
      },
      "source": [
        "- **Both the stocks time-series is not stationary as p-values are much greater than 0.05, hence we cannot reject the null-hypothesis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pwnLVZIU7SH"
      },
      "source": [
        "### Finding degree of differencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0VLGA4rU7SI"
      },
      "outputs": [],
      "source": [
        "# find degree of differencing \n",
        "def degree_of_differencing(df, co_name):\n",
        "    company_ndiffs = ndiffs(df['y'], test = 'adf')\n",
        "    print(f'The degree of differencing is {company_ndiffs} for {co_name}')\n",
        "    \n",
        "    return company_ndiffs\n",
        "\n",
        "aapl_ddf = degree_of_differencing(aplph_df, 'APPLE')\n",
        "fb_ddf = degree_of_differencing(fbph_df, 'Facebook')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhhz9nm0U7SI"
      },
      "source": [
        "### Train forecasting models using Auto-ARIMA\n",
        "\n",
        "- **ARIMA stands for Auto Regessive Integrated Moving Average. The model's goal is to predict future securities or financial market moves by examining the differences between values in the series instead of through the actual values. An ARIMA model can be understood by outlining each of its components as follows:**\n",
        "\n",
        "- **Auto Regression (AR):** Refers to a model that shows a changing variable that regresses on its own lagged or prior values.\n",
        "\n",
        "- **Integrated (I):** Represents the differencing of raw observations to allow for the time series to become stationary (i.e., data values are replaced by the difference between the data values and the previous values).\n",
        "\n",
        "- **Moving Average (MA):** Incorporates the dependency between an observation and a residual error from a moving average model applied to lagged observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pAfFOkQU7SI"
      },
      "outputs": [],
      "source": [
        "# funcrtion to split train and test time-series for modelling purpose\n",
        "def arima_split(df, co_name):\n",
        "    size = int(len(df)*0.95)\n",
        "    train_df = (df['y'])[:size]\n",
        "    test_df = (df['y'])[size:]\n",
        "    \n",
        "    print(f\"data splits of company {co_name}\")\n",
        "    print(f\"Train Size: {len(train_df)}, Test Size: {len(test_df)}\")\n",
        "    print(\"-------------------------------\")\n",
        "    \n",
        "    return train_df, test_df\n",
        "\n",
        "apl_train, apl_test = arima_split(aplph_df, 'APPLE')\n",
        "fb_train, fb_test = arima_split(fbph_df, 'FB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vU7Dsj0U7SI"
      },
      "outputs": [],
      "source": [
        "def find_best_fit_arima(df, co_name):\n",
        "    print(f\"Arima model for {co_name}\")\n",
        "\n",
        "    model = pm.auto_arima(df, test = 'adf', \n",
        "                          start_p = 1, start_q = 1,     \n",
        "                          max_p = 3, max_q = 3,\n",
        "                          d = None, seasonal = True,   \n",
        "                          start_P = 0, m = 3,\n",
        "                          trace = True, error_action = 'ignore',  \n",
        "                          suppress_warnings = True, stepwise = True,\n",
        "                          D = 1, information_criterion = 'aic')\n",
        "\n",
        "    print(model.summary())\n",
        "    print('\\n')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model_apl = find_best_fit_arima(apl_train, 'APPLE')\n",
        "model_fb = find_best_fit_arima(fb_train, 'FB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpw6wGXZU7SI"
      },
      "outputs": [],
      "source": [
        "# let's plot forecasting models plots\n",
        "def display_model_plots(model, co_name):\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    model.plot_diagnostics(figsize = (20, 15));\n",
        "    plt.suptitle(f'Model diagnostics of {co_name}', fontsize = 25)\n",
        "    plt.subplots_adjust(top = 0.93)\n",
        "    plt.show()\n",
        "    plt.style.use('default')\n",
        "    \n",
        "display_model_plots(model_apl, 'AAPL')\n",
        "print(\"-------\"*20)\n",
        "display_model_plots(model_fb, 'FB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLpL2TnPU7SI"
      },
      "source": [
        "**Model diagnostics interpretation:**\n",
        "\n",
        "**1) Standardized residual:** It is an error term of price forecating and actual price of stocks\n",
        "\n",
        "**2) Histogram plus estimated density:** Histogram reresents normal distribution of errors, KDE plots and N(0,1) is notation of indicate mean is ZERO and variance of the distribution is ONE.\n",
        "\n",
        "**3) Normal Q-Q:** Normal Q-Q plot implies normality of distribution as sample quantities mostly inline with theoretical quanitites. any deviation in such alignment would indicate distribution is skewed, or in layman terms error is either positive or negative side.\n",
        "\n",
        "**4) Correlogram:** It simply indicates partial auto-correlation of time-series and shows which laged time-series is significant in forecasting actual time-series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TU1qLuXU7SI"
      },
      "source": [
        "### Forecasting on test data and calculating RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGXJDonpU7SI"
      },
      "outputs": [],
      "source": [
        "def make_predictions_and_print_rmse(model, test_df, co_name):\n",
        "    print(f\"forecasting and RMSE of {co_name}\")\n",
        "    \n",
        "    forecast, confidence_interval = model.predict(X=test_df, n_periods = len(test_df), return_conf_int = True)\n",
        "    forecasts = pd.Series(forecast, index = test_df[:len(test_df)].index)\n",
        "    lower = pd.Series(confidence_interval[:, 0], index = test_df[:len(test_df)].index)\n",
        "    upper = pd.Series(confidence_interval[:, 1], index = test_df[:len(test_df)].index)\n",
        "    \n",
        "    rmse = np.sqrt(np.mean((forecast.values - test_df.values) ** 2))\n",
        "    \n",
        "    print(\"RMSE is: \", rmse)\n",
        "    \n",
        "    return forecasts, lower, upper\n",
        "\n",
        "forecast, lower, upper = make_predictions_and_print_rmse(model_apl, apl_test, 'APPLE')\n",
        "print(\"----------------------------\")\n",
        "forecastf, lowerf, upperf = make_predictions_and_print_rmse(model_fb, fb_test, 'FB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia-nquqgU7SJ"
      },
      "source": [
        "# <h1 style='background:green; border:0; border-radius: 10px; color:black'><center> Conclusion </center></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxuUKUXxU7SJ"
      },
      "source": [
        "**1. In this notebook, we learned saw detailed analysis of time-series to find insights and findout best stocks among all the stocks** \n",
        "\n",
        "**2. We visualized stock prices and proved hypothesis of daily return of stocks**\n",
        "\n",
        "**3. Finally, we built two different forecasting models usgin 'Prophet' and Auto-ARIMA' models to forecast future values of time-series**\n",
        "\n",
        "**4. We found noth time-series being non-stationary and their degrees of differencing were 1.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}